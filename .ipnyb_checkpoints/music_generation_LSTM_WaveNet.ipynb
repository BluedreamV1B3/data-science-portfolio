{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Libraries\n",
    "\n",
    "* Read In Data\n",
    "\n",
    "* Data Preparation\n",
    "\n",
    "* Modeling\n",
    "\n",
    "    * LSTM\n",
    "\n",
    "    * WaveNet\n",
    "\n",
    "* Generate New Chorale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloads the Bach chorales dataset and unzips it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\datasets\\\\data_bach_chorales.tgz'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.get_file(\n",
    "    \"data_bach_chorales.tgz\",\n",
    "    \"https://github.com/ageron/data/raw/main/jsb_chorales.tgz\",\n",
    "    cache_dir=\".\",\n",
    "    extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"datasets/data_bach_chorales\")\n",
    "train = sorted(path .glob(\"train/chorale_*.csv\"))\n",
    "validation = sorted(path .glob(\"valid/chorale_*.csv\"))\n",
    "test = sorted(path .glob(\"test/chorale_*.csv\"))\n",
    "\n",
    "\n",
    "def load_data(filepaths):\n",
    "    return [pd.read_csv(file).values.tolist() for file in filepaths]\n",
    "\n",
    "train = load_data(train)\n",
    "validation = load_data(validation)\n",
    "test = load_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A separate test set is unnecessary for this task because I'll evaluate the model's performance by simply listening to the music it generates. Consequently, I'll merge the test set with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train + test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A typical chorale's length ranges from 100 to 640 time steps. Each time step consists of four integers, where each integer is associated with a piano note index. The value 0 represents the absence of a played note. Here's an illustration of what a chorale, drawn from the training set, might resemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[71, 66, 63, 59],\n",
       " [71, 66, 63, 59],\n",
       " [71, 66, 63, 57],\n",
       " [71, 66, 63, 57],\n",
       " [71, 67, 64, 55],\n",
       " [71, 67, 64, 55],\n",
       " [71, 67, 64, 52],\n",
       " [71, 67, 64, 52],\n",
       " [69, 64, 57, 49],\n",
       " [69, 64, 57, 49],\n",
       " [67, 64, 57, 49],\n",
       " [67, 64, 57, 49],\n",
       " [66, 62, 57, 50],\n",
       " [66, 62, 57, 50],\n",
       " [66, 62, 57, 50],\n",
       " [66, 62, 57, 50],\n",
       " [71, 67, 62, 47],\n",
       " [71, 67, 62, 47],\n",
       " [71, 67, 62, 43],\n",
       " [71, 67, 62, 43],\n",
       " [69, 66, 62, 50],\n",
       " [69, 66, 62, 50],\n",
       " [67, 66, 62, 50],\n",
       " [67, 66, 62, 50],\n",
       " [66, 66, 60, 51],\n",
       " [66, 66, 60, 51],\n",
       " [66, 66, 59, 51],\n",
       " [66, 66, 59, 51],\n",
       " [67, 64, 59, 52],\n",
       " [67, 64, 59, 52],\n",
       " [67, 64, 59, 52],\n",
       " [67, 64, 59, 52],\n",
       " [71, 68, 64, 52],\n",
       " [71, 68, 64, 52],\n",
       " [71, 68, 64, 50],\n",
       " [71, 68, 64, 50],\n",
       " [71, 64, 64, 48],\n",
       " [71, 64, 64, 48],\n",
       " [71, 64, 64, 48],\n",
       " [71, 64, 64, 48],\n",
       " [69, 64, 57, 49],\n",
       " [69, 64, 57, 49],\n",
       " [67, 64, 57, 49],\n",
       " [67, 64, 57, 49],\n",
       " [66, 64, 57, 50],\n",
       " [66, 64, 57, 50],\n",
       " [66, 62, 57, 50],\n",
       " [66, 62, 57, 50],\n",
       " [71, 62, 53, 44],\n",
       " [71, 62, 53, 44],\n",
       " [71, 62, 53, 44],\n",
       " [71, 62, 53, 44],\n",
       " [69, 60, 52, 45],\n",
       " [69, 60, 52, 45],\n",
       " [67, 60, 52, 45],\n",
       " [67, 60, 52, 45],\n",
       " [66, 60, 54, 39],\n",
       " [66, 60, 54, 39],\n",
       " [66, 59, 54, 39],\n",
       " [66, 59, 54, 39],\n",
       " [67, 59, 52, 40],\n",
       " [67, 59, 52, 40],\n",
       " [67, 59, 52, 40],\n",
       " [67, 59, 52, 40],\n",
       " [71, 67, 59, 52],\n",
       " [71, 67, 59, 52],\n",
       " [71, 67, 59, 52],\n",
       " [71, 67, 59, 52],\n",
       " [73, 67, 57, 45],\n",
       " [73, 67, 57, 45],\n",
       " [73, 67, 57, 45],\n",
       " [73, 67, 57, 45],\n",
       " [75, 66, 59, 57],\n",
       " [75, 66, 59, 57],\n",
       " [75, 66, 59, 57],\n",
       " [75, 66, 59, 57],\n",
       " [76, 64, 59, 56],\n",
       " [76, 64, 59, 56],\n",
       " [76, 64, 59, 56],\n",
       " [76, 64, 59, 56],\n",
       " [71, 64, 59, 55],\n",
       " [71, 64, 59, 55],\n",
       " [73, 64, 59, 55],\n",
       " [73, 64, 59, 55],\n",
       " [74, 66, 59, 54],\n",
       " [74, 66, 59, 54],\n",
       " [74, 66, 59, 52],\n",
       " [74, 66, 59, 52],\n",
       " [73, 66, 58, 54],\n",
       " [73, 66, 58, 54],\n",
       " [73, 66, 64, 54],\n",
       " [73, 66, 64, 54],\n",
       " [71, 66, 62, 47],\n",
       " [71, 66, 62, 47],\n",
       " [71, 66, 62, 47],\n",
       " [71, 66, 62, 47],\n",
       " [73, 66, 61, 46],\n",
       " [73, 66, 61, 46],\n",
       " [73, 66, 61, 46],\n",
       " [73, 66, 61, 46],\n",
       " [74, 66, 61, 47],\n",
       " [74, 66, 61, 47],\n",
       " [74, 66, 59, 47],\n",
       " [74, 66, 59, 47],\n",
       " [73, 66, 59, 54],\n",
       " [73, 66, 59, 54],\n",
       " [73, 66, 57, 54],\n",
       " [73, 66, 57, 54],\n",
       " [71, 66, 59, 55],\n",
       " [71, 66, 59, 55],\n",
       " [71, 62, 59, 54],\n",
       " [71, 62, 59, 54],\n",
       " [71, 67, 59, 52],\n",
       " [71, 67, 59, 52],\n",
       " [71, 66, 59, 50],\n",
       " [71, 66, 59, 50],\n",
       " [69, 64, 60, 48],\n",
       " [69, 64, 60, 48],\n",
       " [67, 64, 59, 48],\n",
       " [67, 64, 59, 48],\n",
       " [66, 62, 57, 50],\n",
       " [66, 62, 57, 50],\n",
       " [66, 60, 57, 50],\n",
       " [66, 60, 57, 50],\n",
       " [67, 59, 55, 43],\n",
       " [67, 59, 55, 43],\n",
       " [67, 59, 55, 43],\n",
       " [67, 59, 55, 43],\n",
       " [69, 64, 55, 49],\n",
       " [69, 64, 55, 49],\n",
       " [69, 64, 55, 49],\n",
       " [69, 64, 55, 49],\n",
       " [69, 62, 54, 50],\n",
       " [69, 62, 54, 50],\n",
       " [69, 62, 54, 50],\n",
       " [69, 62, 54, 50],\n",
       " [71, 62, 55, 43],\n",
       " [71, 62, 55, 43],\n",
       " [71, 62, 54, 43],\n",
       " [71, 62, 54, 43],\n",
       " [69, 61, 52, 45],\n",
       " [69, 61, 52, 45],\n",
       " [67, 61, 52, 45],\n",
       " [67, 61, 52, 45],\n",
       " [66, 63, 59, 47],\n",
       " [66, 63, 59, 47],\n",
       " [66, 63, 59, 47],\n",
       " [66, 63, 59, 47],\n",
       " [67, 64, 59, 40],\n",
       " [67, 64, 59, 40],\n",
       " [67, 64, 59, 42],\n",
       " [67, 64, 59, 42],\n",
       " [67, 64, 59, 43],\n",
       " [67, 64, 59, 43],\n",
       " [67, 64, 59, 45],\n",
       " [67, 64, 59, 45],\n",
       " [66, 64, 59, 47],\n",
       " [66, 64, 59, 47],\n",
       " [66, 62, 59, 47],\n",
       " [66, 62, 59, 47],\n",
       " [73, 66, 61, 46],\n",
       " [73, 66, 61, 46],\n",
       " [73, 66, 61, 46],\n",
       " [73, 66, 61, 46],\n",
       " [74, 66, 59, 47],\n",
       " [74, 66, 59, 47],\n",
       " [74, 66, 59, 47],\n",
       " [74, 66, 59, 47],\n",
       " [73, 67, 58, 52],\n",
       " [73, 67, 58, 52],\n",
       " [73, 67, 58, 52],\n",
       " [73, 67, 58, 52],\n",
       " [71, 66, 59, 50],\n",
       " [71, 66, 59, 50],\n",
       " [71, 66, 61, 49],\n",
       " [71, 66, 61, 49],\n",
       " [66, 66, 62, 47],\n",
       " [66, 66, 62, 47],\n",
       " [66, 66, 61, 45],\n",
       " [66, 66, 61, 45],\n",
       " [71, 66, 59, 44],\n",
       " [71, 66, 59, 44],\n",
       " [71, 66, 59, 44],\n",
       " [71, 66, 59, 44],\n",
       " [71, 65, 61, 49],\n",
       " [71, 65, 61, 49],\n",
       " [71, 65, 61, 49],\n",
       " [71, 65, 61, 49],\n",
       " [70, 66, 61, 42],\n",
       " [70, 66, 61, 42],\n",
       " [70, 66, 61, 42],\n",
       " [70, 66, 61, 42],\n",
       " [70, 66, 61, 42],\n",
       " [70, 66, 61, 42],\n",
       " [70, 66, 61, 42],\n",
       " [70, 66, 61, 42]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the distribution of the notes in a sample of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Flatten the data\n",
    "train_data_flat = np.array(train[0]).flatten()\n",
    "\n",
    "# Create a histogram to visualize the data distribution\n",
    "plt.hist(train_data_flat, bins=30, edgecolor='k', alpha=0.7)\n",
    "plt.xlabel('notes')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f\"Frequency of notes in training data\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the min and the max notes across train, validation , and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = set()\n",
    "for chorales in (train, validation, test):\n",
    "    for chorale in chorales:\n",
    "        for chord in chorale:\n",
    "            notes |= set(chord)\n",
    "\n",
    "n_notes = len(notes)\n",
    "min_note = min(notes - {0})\n",
    "max_note = max(notes)\n",
    "\n",
    "assert min_note == 36\n",
    "assert max_note == 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_notes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notes cover a span from 36 (representing C1, which is the C note in the first octave) to 81 (indicating A5, which is the A note in the fifth octave), with an additional value of 0 to denote silence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thanks for the code from https://stackoverflow.com/questions/63974543/how-can-i-play-music-represented-as-chords-in-a-csv-file-with-python\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "def notes_to_frequencies(notes):\n",
    "    # Frequency doubles when you go up one octave; there are 12 semi-tones\n",
    "    # per octave; Note A on octave 4 is 440 Hz, and it is note number 69.\n",
    "    return 2 ** ((np.array(notes) - 69) / 12) * 440\n",
    "\n",
    "def frequencies_to_samples(frequencies, tempo, sample_rate):\n",
    "    note_duration = 60 / tempo # the tempo is measured in beats per minutes\n",
    "    # To reduce click sound at every beat, we round the frequencies to try to\n",
    "    # get the samples close to zero at the end of each note.\n",
    "    frequencies = (note_duration * frequencies).round() / note_duration\n",
    "    n_samples = int(note_duration * sample_rate)\n",
    "    time = np.linspace(0, note_duration, n_samples)\n",
    "    sine_waves = np.sin(2 * np.pi * frequencies.reshape(-1, 1) * time)\n",
    "    # Removing all notes with frequencies â‰¤ 9 Hz (includes note 0 = silence)\n",
    "    sine_waves *= (frequencies > 9.).reshape(-1, 1)\n",
    "    return sine_waves.reshape(-1)\n",
    "\n",
    "def chords_to_samples(chords, tempo, sample_rate):\n",
    "    freqs = notes_to_frequencies(chords)\n",
    "    freqs = np.r_[freqs, freqs[-1:]] # make last note a bit longer\n",
    "    merged = np.mean([frequencies_to_samples(melody, tempo, sample_rate)\n",
    "                     for melody in freqs.T], axis=0)\n",
    "    n_fade_out_samples = sample_rate * 60 // tempo # fade out last note\n",
    "    fade_out = np.linspace(1., 0., n_fade_out_samples)**2\n",
    "    merged[-n_fade_out_samples:] *= fade_out\n",
    "    return merged\n",
    "\n",
    "def play_chords(chords, tempo=160, amplitude=0.1, sample_rate=44100, filepath=None):\n",
    "    samples = amplitude * chords_to_samples(chords, tempo, sample_rate)\n",
    "    if filepath:\n",
    "        from scipy.io import wavfile\n",
    "        samples = (2**15 * samples).astype(np.int16)\n",
    "        wavfile.write(filepath, sample_rate, samples)\n",
    "        return display(Audio(filepath))\n",
    "    else:\n",
    "        return display(Audio(samples, rate=sample_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(5):\n",
    "    play_chords(train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable the generation of new chorales, I aim to train a model capable of predicting the next note by considering the previous notes. Instead of predicting all four notes in a chord simultaneously, which can lead to dissonance, it's more effective to predict one note at a time. Consequently, I need to preprocess each chorale, transforming  each chorale into a long sequence of notes instead of chords. The training approach will involve a sequence-to-sequence model, where I provide a window of notes to the neural network, and it endeavors to forecast that same window shifted forward by one time step.\n",
    "\n",
    "I will also adjust the note values within a range of 0 to 46, with 0 signifying silence, and values 1 to 46 corresponding to notes from C1 (36) to A5 (81).\n",
    "\n",
    "The training process will employ windows of 128 notes, which is equivalent to 32 chords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(batch):\n",
    "    X = batch[:, :-1]\n",
    "    Y = batch[:, 1:] # predict next note in each arpegio, at each step\n",
    "    return X, Y\n",
    "\n",
    "def preprocess(window):\n",
    "    window = tf.where(window == 0, window, window - min_note + 1) # shift values within a range of 0 to 46\n",
    "    return tf.reshape(window, [-1]) # convert into a long sequence of notes\n",
    "\n",
    "def bach_dataset(chorales, batch_size=32, shuffle_buffer_size=None,\n",
    "                 window_size=32, window_shift=16, cache=True):\n",
    "    def batch_window(window):\n",
    "        return window.batch(window_size + 1)\n",
    "\n",
    "    def to_windows(chorale):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(chorale)\n",
    "        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)\n",
    "        return dataset.flat_map(batch_window)\n",
    "\n",
    "    chorales = tf.ragged.constant(chorales, ragged_rank=1)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(chorales)\n",
    "    dataset = dataset.flat_map(to_windows).map(preprocess)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(create_target)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = bach_dataset(train, shuffle_buffer_size=1000)\n",
    "validation = bach_dataset(validation)\n",
    "test = bach_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To provide the model with note values, utilizing floating-point numbers directly might not yield optimal results. The relationships between notes are intricate; for instance, replacing a C3 with a C4 can still sound harmonious, despite the 12 semitones (one octave) difference. On the other hand, substituting a C3 with a C#3 often results in a discordant chord, even though these notes are adjacent on the piano.\n",
    "\n",
    "To address this complexity, I will employ an Embedding layer in each model to convert each note into a compact vector representation. These embeddings will be five-dimensional, and the output of this initial layer will have a shape of [batch_size, window_size, 5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimensions = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 5)           235       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 128)         68608     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, None, 128)         131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 256)         33024     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 47)          12079     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 245,530\n",
      "Trainable params: 245,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_notes, output_dim=embedding_dimensions,\n",
    "                           input_shape=[None]),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(n_notes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "131/131 [==============================] - 18s 123ms/step - loss: 3.3842 - accuracy: 0.0799 - val_loss: 3.2104 - val_accuracy: 0.0960\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 15s 115ms/step - loss: 3.1044 - accuracy: 0.1195 - val_loss: 2.9756 - val_accuracy: 0.1429\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 15s 116ms/step - loss: 2.8235 - accuracy: 0.1732 - val_loss: 2.5851 - val_accuracy: 0.2537\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 15s 116ms/step - loss: 1.9463 - accuracy: 0.4388 - val_loss: 1.5272 - val_accuracy: 0.5604\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 15s 116ms/step - loss: 1.3942 - accuracy: 0.6002 - val_loss: 1.2842 - val_accuracy: 0.6328\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 15s 116ms/step - loss: 1.1895 - accuracy: 0.6605 - val_loss: 1.1221 - val_accuracy: 0.6846\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 15s 115ms/step - loss: 1.0495 - accuracy: 0.7013 - val_loss: 1.0085 - val_accuracy: 0.7162\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 15s 115ms/step - loss: 0.9496 - accuracy: 0.7283 - val_loss: 0.9400 - val_accuracy: 0.7345\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 15s 115ms/step - loss: 0.8680 - accuracy: 0.7493 - val_loss: 0.8519 - val_accuracy: 0.7565\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 15s 115ms/step - loss: 0.7860 - accuracy: 0.7700 - val_loss: 0.7841 - val_accuracy: 0.7723\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 15s 116ms/step - loss: 0.7191 - accuracy: 0.7872 - val_loss: 0.7350 - val_accuracy: 0.7841\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 15s 117ms/step - loss: 0.6714 - accuracy: 0.7991 - val_loss: 0.6983 - val_accuracy: 0.7940\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 15s 115ms/step - loss: 0.6358 - accuracy: 0.8088 - val_loss: 0.6731 - val_accuracy: 0.8009\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 16s 120ms/step - loss: 0.6074 - accuracy: 0.8162 - val_loss: 0.6511 - val_accuracy: 0.8062\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 15s 117ms/step - loss: 0.5850 - accuracy: 0.8223 - val_loss: 0.6334 - val_accuracy: 0.8112\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 16s 119ms/step - loss: 0.5637 - accuracy: 0.8280 - val_loss: 0.6176 - val_accuracy: 0.8161\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 15s 117ms/step - loss: 0.5457 - accuracy: 0.8327 - val_loss: 0.6041 - val_accuracy: 0.8198\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 16s 121ms/step - loss: 0.5302 - accuracy: 0.8368 - val_loss: 0.5987 - val_accuracy: 0.8211\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 16s 119ms/step - loss: 0.5165 - accuracy: 0.8405 - val_loss: 0.5878 - val_accuracy: 0.8242\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 16s 119ms/step - loss: 0.5044 - accuracy: 0.8440 - val_loss: 0.5879 - val_accuracy: 0.8230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cb28aaf690>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3)\n",
    "lstm_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "lstm_model.fit(train, epochs=20, validation_data=validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WaveNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network architecture will resemble a scaled-down version of WaveNet, consisting of a sequence of four Conv1D layers with increasing dilation rates. BatchNormalization layers will be inserted between these convolutional layers to enhance training convergence. Following this, there will be one LSTM layer to capture longer-term patterns, and a Dense layer to generate the ultimate note probabilities. Each probability will correspond to an individual chorale in the batch, for each time step, and for every potential note, including silence. Consequently, the output shape will be [batch_size, window_size, 47]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 5)           235       \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 64)          704       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 64)         256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 128)         16512     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, None, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, None, 256)         65792     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, None, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, None, 512)         262656    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, None, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 256)         787456    \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 47)          12079     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,149,274\n",
      "Trainable params: 1,147,354\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "wavenet_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=n_notes, output_dim=embedding_dimensions,\n",
    "                           input_shape=[None]),\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    tf.keras.layers.Conv1D(128, kernel_size=2, padding=\"causal\", activation=\"relu\",dilation_rate=2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "\n",
    "    \n",
    "    tf.keras.layers.Conv1D(256, kernel_size=2, padding=\"causal\", activation=\"relu\",dilation_rate=4),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    " \n",
    "    tf.keras.layers.Conv1D(512, kernel_size=2, padding=\"causal\", activation=\"relu\",dilation_rate=8),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    " \n",
    "    \n",
    "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "    tf.keras.layers.Dense(n_notes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "wavenet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131/131 [==============================] - 66s 482ms/step - loss: 1.1441 - accuracy: 0.7082 - val_loss: 3.7478 - val_accuracy: 0.0786\n",
      "Epoch 2/20\n",
      "131/131 [==============================] - 64s 492ms/step - loss: 0.5891 - accuracy: 0.8280 - val_loss: 3.7355 - val_accuracy: 0.0948\n",
      "Epoch 3/20\n",
      "131/131 [==============================] - 66s 504ms/step - loss: 0.4886 - accuracy: 0.8530 - val_loss: 3.0460 - val_accuracy: 0.2215\n",
      "Epoch 4/20\n",
      "131/131 [==============================] - 63s 484ms/step - loss: 0.4230 - accuracy: 0.8709 - val_loss: 1.5807 - val_accuracy: 0.5327\n",
      "Epoch 5/20\n",
      "131/131 [==============================] - 61s 464ms/step - loss: 0.3672 - accuracy: 0.8872 - val_loss: 0.6891 - val_accuracy: 0.8035\n",
      "Epoch 6/20\n",
      "131/131 [==============================] - 61s 464ms/step - loss: 0.3224 - accuracy: 0.9007 - val_loss: 0.5797 - val_accuracy: 0.8338\n",
      "Epoch 7/20\n",
      "131/131 [==============================] - 61s 465ms/step - loss: 0.2862 - accuracy: 0.9111 - val_loss: 0.5928 - val_accuracy: 0.8318\n",
      "Epoch 8/20\n",
      "131/131 [==============================] - 64s 485ms/step - loss: 0.2557 - accuracy: 0.9207 - val_loss: 0.5994 - val_accuracy: 0.8323\n",
      "Epoch 9/20\n",
      "131/131 [==============================] - 62s 473ms/step - loss: 0.2330 - accuracy: 0.9278 - val_loss: 0.6163 - val_accuracy: 0.8307\n",
      "Epoch 10/20\n",
      "131/131 [==============================] - 66s 505ms/step - loss: 0.2123 - accuracy: 0.9341 - val_loss: 0.6320 - val_accuracy: 0.8287\n",
      "Epoch 11/20\n",
      "131/131 [==============================] - 66s 501ms/step - loss: 0.1963 - accuracy: 0.9388 - val_loss: 0.6458 - val_accuracy: 0.8263\n",
      "Epoch 12/20\n",
      "131/131 [==============================] - 70s 531ms/step - loss: 0.1808 - accuracy: 0.9436 - val_loss: 0.6638 - val_accuracy: 0.8269\n",
      "Epoch 13/20\n",
      "131/131 [==============================] - 69s 530ms/step - loss: 0.1716 - accuracy: 0.9465 - val_loss: 0.6724 - val_accuracy: 0.8269\n",
      "Epoch 14/20\n",
      "131/131 [==============================] - 68s 521ms/step - loss: 0.1633 - accuracy: 0.9488 - val_loss: 0.6797 - val_accuracy: 0.8268\n",
      "Epoch 15/20\n",
      "131/131 [==============================] - 71s 538ms/step - loss: 0.1554 - accuracy: 0.9513 - val_loss: 0.6984 - val_accuracy: 0.8262\n",
      "Epoch 16/20\n",
      "131/131 [==============================] - 69s 530ms/step - loss: 0.1506 - accuracy: 0.9523 - val_loss: 0.7118 - val_accuracy: 0.8236\n",
      "Epoch 17/20\n",
      "131/131 [==============================] - 70s 534ms/step - loss: 0.1451 - accuracy: 0.9539 - val_loss: 0.7136 - val_accuracy: 0.8263\n",
      "Epoch 18/20\n",
      "131/131 [==============================] - 61s 466ms/step - loss: 0.1415 - accuracy: 0.9547 - val_loss: 0.7331 - val_accuracy: 0.8243\n",
      "Epoch 19/20\n",
      "131/131 [==============================] - 60s 459ms/step - loss: 0.1379 - accuracy: 0.9561 - val_loss: 0.7355 - val_accuracy: 0.8227\n",
      "Epoch 20/20\n",
      "131/131 [==============================] - 61s 466ms/step - loss: 0.1335 - accuracy: 0.9571 - val_loss: 0.7518 - val_accuracy: 0.8232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2cb32ccb110>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=1e-3)\n",
    "wavenet_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "wavenet_model.fit(train, epochs=20, validation_data=validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(I will not fine-tuning because the purpose of this notebook is to pratice the end to end pipeline of the sequence model. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Chorale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that generates a novel chorale. I'll input a set of initial chords, transform them into a sequence (as required by the model), and employ the model to forecast the following note in a sequential fashion. Subsequently, I'll group the notes in sets of four to recreate chords and then return the resulting chorale. However, using the model directly presents a risk-averse behavior, as it invariably selects the note with the highest score. Typically, this results in an over-repetition of the previous note, leading to a rather uninteresting musical output. To add more variety, I'll opt for a randomized approach. Instead of always favoring the highest-scoring note, I will make the next note selection based on the predicted probabilities. For instance, if the model suggests a C3 with a 75% probability and a G3 with a 25% probability, it will choose one of these notes randomly, with their respective probabilities considered in the selection process. I'll add a rate parameter. A high rate will bring the predicted probabilities closer together, reducing the probability of the likely notes and increasing the probability of the unlikely ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_chorale(model, initial_chords, length, rate=1):\n",
    "    sequence_notes = preprocess(tf.constant(initial_chords, dtype=tf.int64))\n",
    "    sequence_notes = tf.reshape(sequence_notes, [1, -1])\n",
    "    for chord in range(length):\n",
    "        for note in range(4):\n",
    "            next_note_probas = model.predict(sequence_notes)[0, -1:]\n",
    "            rescaled_logits = tf.math.log(next_note_probas) / rate\n",
    "            next_note = tf.random.categorical(rescaled_logits, num_samples=1)\n",
    "            sequence_notes = tf.concat([sequence_notes, next_note], axis=1)\n",
    "    sequence_notes = tf.where(sequence_notes == 0, sequence_notes, sequence_notes + min_note - 1)\n",
    "    return tf.reshape(sequence_notes, shape=[-1, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize the initial 8 chords from one of the test chorales, which essentially consists of two distinct chords, each played four times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = sorted(path.glob(\"test/chorale_*.csv\"))\n",
    "test_chorales = load_data(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_chords = test_chorales[2][:8]\n",
    "play_chords(initial_chords, amplitude=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chorale1 = my_chorale(wavenet_model, initial_chords, 56, 0.8)\n",
    "play_chords(new_chorale1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chorale2 = my_chorale(wavenet_model, initial_chords, 56, 1.5)\n",
    "play_chords(new_chorale2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_chords(test_chorales[2][:64], filepath=\"original_chorale.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_chords(new_chorale2, filepath=\"new_chorale_.wav\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
